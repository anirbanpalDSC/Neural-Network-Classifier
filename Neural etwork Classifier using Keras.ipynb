{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Neural Network Classifier with Keras**\n",
    "\n",
    "Using the multi-label classifier dataset from earlier exercises (categorized-comments.jsonl in the reddit folder), fit a neural network classifier using Keras. Use the code found in chapter 12 of the Applied Text Analysis with Python book as a guideline. Report the accuracy, precision, recall, F1-score, and confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, numpy as np, json, re, pickle, keras\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_fscore_support\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file):\n",
    "    \"\"\"\n",
    "    Take a json file location and\n",
    "    read the file into a pandas data frame\n",
    "    Args: full path to file\n",
    "    Returns: pandas dataframe with data from file\n",
    "    \"\"\"\n",
    "    \n",
    "    data = []\n",
    "\n",
    "    with open(file) as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line))\n",
    "        \n",
    "    # convert to data frame\n",
    "    \n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2347476 entries, 0 to 2347475\n",
      "Data columns (total 2 columns):\n",
      "cat    object\n",
      "txt    object\n",
      "dtypes: object(2)\n",
      "memory usage: 35.8+ MB\n",
      "Size:  2347476 \n",
      " Shape:  None \n",
      " Categories:  ['sports' 'science_and_technology' 'video_games' 'news']\n"
     ]
    }
   ],
   "source": [
    "# read category data\n",
    "\n",
    "cat_df = read_data('data/reddit/categorized-comments.jsonl')\n",
    "\n",
    "# check size, structure and categories\n",
    "\n",
    "print('Size: ', len(cat_df), '\\n',\n",
    "      'Shape: ', cat_df.info(), '\\n',\n",
    "      'Categories: ', cat_df.cat.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Remove punctuations and special characters, makes lower case\n",
    "    Args: text \n",
    "    Output: text\n",
    "    \"\"\"\n",
    "    \n",
    "    text=text.lower()\n",
    "    text=re.sub('&lt;/?.*?&gt;',' &lt;&gt', text)\n",
    "    text=re.sub('\\\\d|\\\\W+|_',' ',text)\n",
    "    text=re.sub('[^a-zA-Z]',\" \", text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Create stop words list\n",
    "\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>news</td>\n",
       "      <td>about the a the reason behind it was that saud...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>news</td>\n",
       "      <td>you can register as an independent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>news</td>\n",
       "      <td>gt would you call someone sexually attracted ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>news</td>\n",
       "      <td>it can also be argued that it s not enough foo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>news</td>\n",
       "      <td>not an attack like msm wants us to think trump...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cat                                                txt\n",
       "0  news  about the a the reason behind it was that saud...\n",
       "1  news                you can register as an independent \n",
       "2  news   gt would you call someone sexually attracted ...\n",
       "3  news  it can also be argued that it s not enough foo...\n",
       "4  news  not an attack like msm wants us to think trump..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# since the size is humongus, I will take sample of the 2 categories. \n",
    "# by trial, sample of 50000 from each category can be easily handled by my machine\n",
    "\n",
    "size = 50000    # sample size\n",
    "replace = True  # with replacement\n",
    "fn = lambda obj: obj.loc[np.random.choice(obj.index, size, replace),:]\n",
    "\n",
    "category = cat_df.groupby('cat', as_index=False).apply(fn)\n",
    "\n",
    "# free up memory\n",
    "\n",
    "del cat_df\n",
    "\n",
    "category['txt'] = category['txt'].apply(lambda x:clean_text(x))\n",
    "category.reset_index(drop=True, inplace=True)\n",
    "\n",
    "category.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cat\n",
       "news                      50000\n",
       "science_and_technology    50000\n",
       "sports                    50000\n",
       "video_games               50000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the unique categories\n",
    "\n",
    "#category[\"cat\"].unique()\n",
    "category.groupby([\"cat\"]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       txt\n",
       "cat       \n",
       "0    50000\n",
       "1    50000\n",
       "2    50000\n",
       "3    50000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "\n",
    "cat = category[\"cat\"]\n",
    "category[\"cat\"]=encoder.fit_transform(cat)\n",
    "category.groupby(\"cat\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the features and classes\n",
    "\n",
    "N_FEATURES = 5000\n",
    "N_CLASSES = 1\n",
    "N_UNITS = 2500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the feature matrix\n",
    "\n",
    "cv = CountVectorizer(analyzer='word',\n",
    "                     stop_words=stop_words, \n",
    "                     max_features = N_FEATURES,\n",
    "                     max_df = 0.5,\n",
    "                     min_df = 3)\n",
    "\n",
    "# create target and sample\n",
    "\n",
    "X = cv.fit_transform(category['txt'])\n",
    "y = category['cat']\n",
    "\n",
    "# create train test split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple ANN can only take a linear array of features as input. Therefore, checking the train and test dataset accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150000, 5000)\n",
      "(50000, 5000)\n",
      "(150000,)\n",
      "(50000,)\n"
     ]
    }
   ],
   "source": [
    "print(str(X_train.shape))\n",
    "print(str(X_test.shape))\n",
    "print(str(y_train.shape))\n",
    "print(str(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create classifier for ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize\n",
    "\n",
    "classifier_seq = Sequential()\n",
    "\n",
    "classifier_seq.add(Dense(units=500,activation=\"relu\",input_shape=(N_FEATURES,)))\n",
    "classifier_seq.add(Dense(units=50, activation=\"relu\"))\n",
    "classifier_seq.add(Dense(units=4, activation=\"softmax\"))\n",
    "\n",
    "# compile the Artificial Neural Network (ANN)\n",
    "\n",
    "classifier_seq.compile(optimizer=\"rmsprop\", \n",
    "                       loss=\"sparse_categorical_crossentropy\", \n",
    "                       metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "150000/150000 [==============================] - 71s 473us/step - loss: 0.8591 - acc: 0.6470\n",
      "Epoch 2/5\n",
      "150000/150000 [==============================] - 82s 549us/step - loss: 0.7794 - acc: 0.6827\n",
      "Epoch 3/5\n",
      "150000/150000 [==============================] - 80s 532us/step - loss: 0.7187 - acc: 0.70991s - loss: 0.71\n",
      "Epoch 4/5\n",
      "150000/150000 [==============================] - 85s 564us/step - loss: 0.6498 - acc: 0.7398\n",
      "Epoch 5/5\n",
      "150000/150000 [==============================] - 72s 480us/step - loss: 0.5705 - acc: 0.77294s - loss: 0.568 - ETA: 2s -\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25fe47e6f28>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit ANN to the training set\n",
    "\n",
    "classifier_seq.fit(X_train, y_train, batch_size=200, epochs=5, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate model and calculate matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 500)               2500500   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 50)                25050     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 4)                 204       \n",
      "=================================================================\n",
      "Total params: 2,525,754\n",
      "Trainable params: 2,525,754\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier_seq.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 17s 341us/step\n",
      "Training Accuracy: 0.6570\n"
     ]
    }
   ],
   "source": [
    "# loss and accuracy\n",
    "\n",
    "loss, accuracy = classifier_seq.evaluate(X_test, y_test, verbose=1)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create prediction\n",
    "\n",
    "y_pred = classifier_seq.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:  [[8413 1815 1586  792]\n",
      " [2203 8172 1161 1043]\n",
      " [1591  501 8887 1393]\n",
      " [1298 1017 2751 7377]]\n",
      "Classification Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.67      0.64     12606\n",
      "           1       0.71      0.65      0.68     12579\n",
      "           2       0.62      0.72      0.66     12372\n",
      "           3       0.70      0.59      0.64     12443\n",
      "\n",
      "   micro avg       0.66      0.66      0.66     50000\n",
      "   macro avg       0.66      0.66      0.66     50000\n",
      "weighted avg       0.66      0.66      0.66     50000\n",
      "\n",
      "Accuracy:  0.65698\n"
     ]
    }
   ],
   "source": [
    "# calculate model matrix\n",
    "\n",
    "print(\"Confusion Matrix: \", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report: \", classification_report(y_test,y_pred))\n",
    "print(\"Accuracy: \", accuracy_score(y_test,y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
